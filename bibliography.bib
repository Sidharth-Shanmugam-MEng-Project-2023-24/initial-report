@techreport{alexliangBoostingMachineVision2016,
  type = {White {{Paper}}},
  title = {Boosting {{Machine Vision}} with {{Built-in FPGA Image Preprocessing}}},
  author = {{Alex Liang}},
  year = {2016},
  month = may,
  institution = {Measurement \& Automation Product Segment, ADLINK Technology},
  url = {https://qnv.com/wp-content/uploads/catalogos/BoostingMachineVisionwithBuilt-inFPGAImagePreprocessing_webversion.pdf},
  urldate = {2024-02-23},
  abstract = {Since imaging processing tasks can consume major CPU resources in machine vision applications, increasing processing performance within size constraints is, accordingly, a common challenge for solution providers. The following discusses the efficacy of FPGA in addressing such performance shortcomings, presents the image processing tasks most suitable for FPGA, and compares the capabilities of CPU and FPGA in operation. A built-in FPGA image preprocessing solution supporting machine vision applications is then presented.},
  langid = {english}
}

@misc{bootlinUnderstandingLinuxRealtime2024,
  title = {Understanding {{Linux}} Real-Time with {{PREEMPT}}\_{{RT}} Training},
  author = {{Bootlin}},
  year = {2024},
  month = jan,
  urldate = {2024-01-31},
  abstract = {These slides are the training materials for Bootlin's Understanding Linux real-time with PREEMPT\_RT training course.},
  langid = {english}
}

@misc{brentdurandEasyWaysEliminate2013,
  title = {Easy {{Ways}} to {{Eliminate Backscatter}} in Your {{Photos}}},
  author = {{Brent Durand}},
  year = {2013},
  month = oct,
  journal = {Underwater Photography Guide},
  url = {https://www.uwphotographyguide.com/eliminate-backscatter-underwater},
  urldate = {2024-02-14},
  abstract = {Backscatter is the underwater photographer's arch nemesis. We've all taken shots riddled with the distracting white specs, whether they dot the whole picture or form two semi-circles on the edge of the frame. Backscatter can (and often does) destroy an otherwise-excellent image. The good news is that there are some universal techniques for eliminating backscatter that can be applied to a variety of composition styles, from macro to wide-angle. What is Backscatter?},
  langid = {english},
  file = {/Users/sid/Zotero/storage/SMGGXDRG/eliminate-backscatter-underwater.html}
}

@article{cannyComputationalApproachEdge1986,
  title = {A {{Computational Approach}} to {{Edge Detection}}},
  author = {Canny, John},
  year = {1986},
  month = nov,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {PAMI-8},
  number = {6},
  pages = {679--698},
  issn = {0162-8828},
  doi = {10.1109/TPAMI.1986.4767851},
  url = {https://ieeexplore.ieee.org/document/4767851},
  urldate = {2024-02-24}
}

@misc{costashulCyclictest2023,
  title = {Cyclictest},
  author = {{Costa Shul}},
  year = {2023},
  month = aug,
  journal = {realtime:documentation:howto:tools:cyclictest:start [Wiki]},
  url = {https://wiki.linuxfoundation.org/realtime/documentation/howto/tools/cyclictest/start},
  urldate = {2024-03-01},
  abstract = {Cyclictest accurately and repeatedly measures the difference between a thread's intended wake-up time and the time at which it actually wakes up in order to provide statistics about the system's latencies. It can measure latencies in real-time systems caused by the hardware, the firmware, and the operating system.},
  langid = {english},
  file = {/Users/sid/Zotero/storage/CI6QW7S4/start.html}
}

@misc{costashulRTTests2023,
  title = {{{RT-Tests}}},
  author = {{Costa Shul}},
  year = {2023},
  month = sep,
  journal = {realtime:documentation:howto:tools:rt-tests [Wiki]},
  url = {https://wiki.linuxfoundation.org/realtime/documentation/howto/tools/rt-tests},
  urldate = {2024-03-01},
  abstract = {rt-tests is a test suite, that contains programs to test various real time Linux features. It is maintained by Clark Williams and John Kacur. For communication, the rt-users mailing list is used.},
  langid = {english},
  file = {/Users/sid/Zotero/storage/SWMDKQXX/rt-tests.html}
}

@misc{CourseNoteComputer,
  title = {Course {{Note}} of {{Computer Graphics Chapter}} 5},
  url = {https://redirect.cs.umbc.edu/~ebert/435/notes/435_ch5.html},
  urldate = {2024-03-06},
  file = {/Users/sid/Zotero/storage/7TZ5U3AQ/435_ch5.html}
}

@misc{dev22adminGPUVsFPGA2023,
  title = {{{GPU}} vs. {{FPGA}} vs. {{CPU}}: {{A Comparative Analysis}} for {{Image Processing}} in {{AI}} and {{Traditional Machine Vision}}},
  shorttitle = {{{GPU}} vs. {{FPGA}} vs. {{CPU}}},
  author = {Dev22Admin},
  year = {2023},
  month = oct,
  journal = {Sciotex},
  url = {https://sciotex.com/gpu-vs-fpga-vs-cpu-a-comparative-analysis-for-image-processing-in-ai-and-traditional-machine-vision/},
  urldate = {2024-03-06},
  abstract = {Image processing is an essential component in a wide range of applications, from traditional machine vision in industrial automation to cutting-edge artificial intelligence AI Vision Systems that require image recognition and analysis. The choice of hardware for image processing plays a pivotal role in determining the efficiency, accuracy, and performance of these systems. In this [{\dots}]},
  langid = {american},
  file = {/Users/sid/Zotero/storage/M7HH5ACR/gpu-vs-fpga-vs-cpu-a-comparative-analysis-for-image-processing-in-ai-and-traditional-machine-vi.html}
}

@article{DigitalLightProcessing2024,
  title = {Digital {{Light Processing}}},
  year = {2024},
  month = feb,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Digital_Light_Processing&oldid=1201748148},
  urldate = {2024-02-24},
  abstract = {Digital Light Processing (DLP) is a set of chipsets based on optical micro-electro-mechanical technology that uses a digital micromirror device. It was originally developed in 1987 by Larry Hornbeck of Texas Instruments. While the DLP imaging device was invented by Texas Instruments, the first DLP-based projector was introduced by Digital Projection Ltd in 1997. Digital Projection and Texas Instruments were both awarded Emmy Awards in 1998 for the DLP projector technology. DLP is used in a variety of display applications from traditional static displays to interactive displays and also non-traditional embedded applications including medical, security, and industrial uses. DLP technology is used in DLP front projectors (standalone projection units for classrooms and business primarily), DLP rear projection television sets, and digital signs. It is also used in about 85\% of digital cinema projection, and in additive manufacturing as a light source in some printers to cure resins into solid 3D objects.Smaller {${''}$}pico{${''}$} chipsets are used in mobile devices including cell phone accessories and projection display functions embedded directly into phones.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1201748148},
  file = {/Users/sid/Zotero/storage/RDZPLEUL/Digital_Light_Processing.html}
}

@misc{DLP4500DigitalMicromirror,
  title = {{{DLP4500 Digital Micromirror Device}} - {{TI}} {\textbar} {{Mouser}}},
  url = {https://www.mouser.co.uk/new/texas-instruments/ti-dlp4500-micromirror-device/},
  urldate = {2024-02-24},
  file = {/Users/sid/Zotero/storage/27YHAPEL/ti-dlp4500-micromirror-device.html}
}

@misc{FreeRTOSRaspberry2022,
  title = {Free {{RTOS}} on the {{Raspberry Pi}} 4 - {{Kernel}}},
  year = {2022},
  month = aug,
  journal = {FreeRTOS Community Forums},
  url = {https://forums.freertos.org/t/free-rtos-on-the-raspberry-pi-4/15659},
  urldate = {2024-02-29},
  abstract = {21.8.2022  It would be advantageous if the full version of FreeRTOS would be available on the RPi. Great for hobbyists and for teachers alike. There is some sort of port but it is not satisfactory at all.  Is there any chance of such a version becoming available?},
  chapter = {Kernel},
  langid = {english},
  file = {/Users/sid/Zotero/storage/IVSQY8HM/15659.html}
}

@inproceedings{hansenEvaluatingCMAEvolution2004,
  title = {Evaluating the {{CMA Evolution Strategy}} on {{Multimodal Test Functions}}},
  booktitle = {Parallel {{Problem Solving}} from {{Nature}} - {{PPSN VIII}}},
  author = {Hansen, Nikolaus and Kern, Stefan},
  editor = {Yao, Xin and Burke, Edmund K. and Lozano, Jos{\'e} A. and Smith, Jim and {Merelo-Guerv{\'o}s}, Juan Juli{\'a}n and Bullinaria, John A. and Rowe, Jonathan E. and Ti{\v n}o, Peter and Kab{\'a}n, Ata and Schwefel, Hans-Paul},
  year = {2004},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {282--291},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-30217-9_29},
  abstract = {In this paper the performance of the CMA evolution strategy with rank-{$\mu$}-update and weighted recombination is empirically investigated on eight multimodal test functions. In particular the effect of the population size {$\lambda$} on the performance is investigated. Increasing the population size remarkably improves the performance on six of the eight test functions. The optimal population size takes a wide range of values, but, with one exception, scales sub-linearly with the problem dimension. The global optimum can be located in all but one function. The performance for locating the global optimum scales between linear and cubic with the problem dimension. In a comparison to state-of-the-art global search strategies the CMA evolution strategy achieves superior performance on multimodal, non-separable test functions without intricate parameter tuning.},
  isbn = {978-3-540-30217-9},
  langid = {english},
  keywords = {Covariance Matrix Adaptation,Initial Step Size,Large Population Size,Problem Dimension,Rastrigin Function},
  file = {/Users/sid/Zotero/storage/H5R8647C/Hansen and Kern - 2004 - Evaluating the CMA Evolution Strategy on Multimoda.pdf}
}

@misc{HowDLPProjector,
  title = {How {{DLP}} Projector Technology Works - {{YouTube}}},
  url = {https://www.youtube.com/},
  urldate = {2024-02-24},
  abstract = {Enjoy the videos and music that you love, upload original content and share it all with friends, family and the world on YouTube.},
  langid = {british}
}

@misc{HowDoesDLP,
  title = {How Does a {{DLP}} Projector Work?},
  journal = {ProjectorScreen.com},
  url = {https://www.projectorscreen.com/blog/How-does-a-DLP-projector-work},
  urldate = {2024-02-24},
  abstract = {A DLPâ„¢ projector is a projector that utilizes a DLP chipset to produce the image you see on your projector screen. The DLP chip was developed in 1987 by Larry Hornbeck of Texas Instruments. The first DLP projector to use this technology was so...},
  langid = {english}
}

@article{kalmanNewApproachLinear1960,
  title = {A {{New Approach}} to {{Linear Filtering}} and {{Prediction Problems}}},
  author = {Kalman, R. E.},
  year = {1960},
  month = mar,
  journal = {Journal of Basic Engineering},
  volume = {82},
  number = {1},
  pages = {35--45},
  issn = {0021-9223},
  doi = {10.1115/1.3662552},
  url = {https://asmedigitalcollection.asme.org/fluidsengineering/article/82/1/35/397706/A-New-Approach-to-Linear-Filtering-and-Prediction},
  urldate = {2024-02-28},
  abstract = {The classical filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes and the ``state-transition'' method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinite-memory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the co-efficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix.},
  langid = {english}
}

@phdthesis{katieshepherdMachineVisionBased2023,
  type = {{{MEng Project Report}}},
  title = {Machine {{Vision Based Underwater Anti-Backscatter Lighting System}}},
  author = {{Katie Shepherd}},
  year = {2023},
  address = {York, UK},
  urldate = {2023-09-01},
  abstract = {When filming underwater, small spots of debris reflect the light from Unmanned Underwater Vehicles (UUVs) reducing the camera image quality, this is known as backscatter. The purpose of this project is to create a machine vision-based lighting system using a smart projector, to eliminate backscatter from a video feed. In this project, the foundational testing of this anti-backscatter lighting system has been conducted. Previously with the use of image processing on captured images, backscatter has been removed using variations of median filtering. However, this can leave areas of the image blurry where the backscatter has been removed and does not eliminate the backscatter when capturing the video live. In this project with the use of a Raspberry Pi, a high- quality camera and a smart projector, the bright areas of backscatter can be successfully removed in live video feeds. The camera feeds back the position of detected bright spots in the scene, and then black holes are projected in these positions to not illuminate the backscatter, hence eliminating it. The results from testing have found issues with parallax and camera depth perception which make projecting holes accurately very complex, and this needs to be addressed further in future work. The project demonstrates, that with the use of a machine vision-based lighting system, backscatter of a variety of shapes and sizes can be detected and then eliminated from the scene. This project is just the beginning of a larger goal to eliminate backscatter in an underwater environment, and with all the foundational testing conducted successfully in the air, the system is ready to be thoroughly experimented with underwater.},
  langid = {english},
  school = {University of York}
}

@article{kuhnHungarianMethodAssignment1955,
  title = {The {{Hungarian}} Method for the Assignment Problem},
  author = {Kuhn, H. W.},
  year = {1955},
  month = mar,
  journal = {Naval Research Logistics Quarterly},
  volume = {2},
  number = {1-2},
  pages = {83--97},
  issn = {0028-1441, 1931-9193},
  doi = {10.1002/nav.3800020109},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/nav.3800020109},
  urldate = {2024-02-28},
  abstract = {Abstract             Assuming that numerical scores are available for the performance of each of n persons on each of n jobs, the ``assignment problem'' is the quest for an assignment of persons to jobs so that the sum of the n scores so obtained is as large as possible. It is shown that ideas latent in the work of two Hungarian mathematicians may be exploited to yield a new method of solving this problem.},
  langid = {english},
  file = {/Users/sid/Zotero/storage/Z6FTQB22/Kuhn - 1955 - The Hungarian method for the assignment problem.pdf}
}

@misc{maurorivaRaspberryPi4B2019,
  title = {Raspberry {{Pi 4B}}: {{Real-Time System}} Using {{Preempt-RT}} (Kernel 4.19.y)},
  author = {{Mauro Riva}},
  year = {2019},
  month = sep,
  journal = {LeMaRiva{\textbar}tech},
  url = {https://lemariva.com/blog/2019/09/raspberry-pi-4b-preempt-rt-kernel-419y-performance-test},
  urldate = {2024-03-01},
  abstract = {This article is about testing the performance of the Raspberry Pi 4B to run Python algorithms on a Standard and Preempt-RT patched kernel. A tutorial to patch Kernel v.4.19.y is also included. A benchmark based on the N-queens problem written in Python is used to analyse the performance of the different kernels.},
  langid = {english},
  file = {/Users/sid/Zotero/storage/G3GUIX3U/raspberry-pi-4b-preempt-rt-kernel-419y-performance-test.html}
}

@misc{MeasurePropertiesImage,
  title = {Measure Properties of Image Regions - {{MATLAB}} Regionprops - {{MathWorks United Kingdom}}},
  url = {https://uk.mathworks.com/help/images/ref/regionprops.html},
  urldate = {2024-03-06},
  file = {/Users/sid/Zotero/storage/HQE57VM4/regionprops.html}
}

@misc{MeasureRegionProperties,
  title = {Measure Region Properties --- Skimage 0.22.0 Documentation},
  url = {https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_regionprops.html},
  urldate = {2024-03-06},
  file = {/Users/sid/Zotero/storage/FSCUCLPS/plot_regionprops.html}
}

@misc{nlightnfotisAnswerWhatDifference2013,
  title = {Answer to "{{What}} Is Difference between {{User}} Space and {{Kernel}} Space?"},
  shorttitle = {Answer to "{{What}} Is Difference between {{User}} Space and {{Kernel}} Space?},
  author = {NlightNFotis},
  year = {2013},
  month = aug,
  journal = {Unix \& Linux Stack Exchange},
  url = {https://unix.stackexchange.com/a/87629},
  urldate = {2024-03-06},
  file = {/Users/sid/Zotero/storage/QW9GZLK2/what-is-difference-between-user-space-and-kernel-space.html}
}

@misc{opencv,
  title = {About},
  author = {{OpenCV}},
  journal = {OpenCV},
  url = {https://opencv.org/about/},
  urldate = {2024-03-01},
  abstract = {OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library. OpenCV was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in the commercial products. Being an Apache 2 licensed product, OpenCV makes it easy for businesses to utilize and modify the code.},
  langid = {american}
}

@misc{opencvOpenCVCvSimpleBlobDetector,
  title = {{{OpenCV}}: Cv::{{SimpleBlobDetector Class Reference}}},
  author = {{OpenCV}},
  url = {https://docs.opencv.org/3.4/d0/d7a/classcv_1_1SimpleBlobDetector.html},
  urldate = {2024-03-05},
  file = {/Users/sid/Zotero/storage/T7VYPJQ8/classcv_1_1SimpleBlobDetector.html}
}

@misc{raspberrypiltdBuyRaspberryPi,
  title = {Buy a {{Raspberry Pi}} 4 {{Model B}}},
  author = {{Raspberry Pi Ltd}},
  journal = {Raspberry Pi},
  url = {https://www.raspberrypi.com/products/raspberry-pi-4-model-b/},
  urldate = {2024-02-23},
  abstract = {Your tiny, dual-display, desktop~computer {\dots}and robot brains, smart home hub, media centre, networked AI core, factory controller, and much more.},
  langid = {british},
  file = {/Users/sid/Zotero/storage/SICZVKBS/raspberry-pi-4-model-b.html}
}

@misc{raspberrypiltdBuyRaspberryPia,
  title = {Buy a {{Raspberry Pi}} 5},
  author = {{Raspberry Pi Ltd}},
  journal = {Raspberry Pi},
  url = {https://www.raspberrypi.com/products/raspberry-pi-5/},
  urldate = {2024-02-23},
  abstract = {The everything computer. Optimised.},
  langid = {british},
  file = {/Users/sid/Zotero/storage/D5V5TGBS/raspberry-pi-5.html}
}

@misc{raspberrypiltdBuyRaspberryPib,
  title = {Buy a {{Raspberry Pi Global Shutter Camera}}},
  author = {{Raspberry Pi Ltd}},
  journal = {Raspberry Pi},
  url = {https://www.raspberrypi.com/products/raspberry-pi-global-shutter-camera/},
  urldate = {2024-02-24},
  abstract = {A specialised camera for fast motion photography and machine vision applications},
  langid = {british},
  file = {/Users/sid/Zotero/storage/RWKFC3C5/raspberry-pi-global-shutter-camera.html}
}

@misc{raspberrypiRaspberryPiUs,
  title = {Raspberry {{Pi}} - {{About}} Us},
  author = {{Raspberry Pi}},
  journal = {Raspberry Pi},
  url = {https://www.raspberrypi.com/about/},
  urldate = {2024-02-23},
  abstract = {Raspberry Pi makes inexpensive, small computers for home, industry, education and much more.},
  langid = {british}
}

@misc{rayryengAnswerExplanationMatlab2014,
  title = {Answer to "{{Explanation}} of {{Matlab}}'s Bwlabel,Regionprops \& Centroid Functions"},
  author = {{rayryeng}},
  year = {2014},
  month = sep,
  journal = {Stack Overflow},
  url = {https://stackoverflow.com/a/25984775},
  urldate = {2024-03-06},
  file = {/Users/sid/Zotero/storage/BNJTUJIN/explanation-of-matlabs-bwlabel-regionprops-centroid-functions.html}
}

@misc{reddigitalcinemaGlobalRollingShutters,
  title = {Global \& {{Rolling Shutters}}},
  author = {{RED Digital Cinema}},
  journal = {Global \& Rolling Shutters},
  url = {https://www.red.com/red-101/global-rolling-shutter},
  urldate = {2024-02-24},
  abstract = {A camera's shutter determines how and when light gets recorded during an exposure. In this article, we'll explore the various shutter mechanisms that have been implemented, ranging from early film to recent digital cameras.},
  file = {/Users/sid/Zotero/storage/MN6VK2MZ/global-rolling-shutter.html}
}

@misc{RollingShutterVs,
  title = {Rolling {{Shutter}} vs {{Global Shutter sCMOS Camera Mode}}},
  journal = {Oxford Instruments},
  url = {https://andor.oxinst.com/learning/view/article/rolling-and-global-shutter},
  urldate = {2024-02-24},
  abstract = {This article outlines the differences between Rolling Shutter vs Global Shutter camera modes. Discover the mode that best suits your needs},
  langid = {english},
  file = {/Users/sid/Zotero/storage/IY5G9II2/rolling-and-global-shutter.html}
}

@misc{steveeddinsEllipseVisualizationRegionprops2015,
  title = {Ellipse Visualization and Regionprops},
  author = {{Steve Eddins}},
  year = {2015},
  month = aug,
  journal = {Steve on Image Processing with MATLAB},
  url = {https://blogs.mathworks.com/steve/2015/08/17/ellipse-visualization-and-regionprops/},
  urldate = {2024-03-06},
  abstract = {A blog reader asked me recently how to visualize the ellipse-based measurements computed by regionprops. The reader wanted to superimpose the estimated ellipses on the image.To refresh your memory: The function regionprops, which computes geometrical measurements of image regions, offers several measurements that are based on fitting an ellipse to the region. (If you must know, the ellipse fit is},
  langid = {english},
  file = {/Users/sid/Zotero/storage/Q47I4Q4K/ellipse-visualization-and-regionprops.html}
}

@misc{theodoreWhatExactlyBlob,
  title = {What Exactly Is a {{Blob}} in {{OpenCV}} ? - {{OpenCV Q}}\&{{A Forum}}},
  author = {{theodore}},
  url = {https://answers.opencv.org/question/50025/what-exactly-is-a-blob-in-opencv/},
  urldate = {2024-03-05},
  file = {/Users/sid/Zotero/storage/RDE6WBT6/what-exactly-is-a-blob-in-opencv.html}
}

@article{thomanekAutomatedGasBubble2010,
  title = {Automated Gas Bubble Imaging at Sea Floor - a New Method of in Situ Gas Flux Quantification},
  author = {Thomanek, K. and Zielinski, O. and Sahling, H. and Bohrmann, G.},
  year = {2010},
  month = jun,
  journal = {Ocean Science},
  volume = {6},
  number = {2},
  pages = {549--562},
  publisher = {Copernicus GmbH},
  issn = {1812-0784},
  doi = {10.5194/os-6-549-2010},
  url = {https://os.copernicus.org/articles/6/549/2010/},
  urldate = {2024-02-24},
  abstract = {Photo-optical systems are common in marine sciences and have been extensively used in coastal and deep-sea research. However, due to technical limitations in the past photo images had to be processed manually or semi-automatically. Recent advances in technology have rapidly improved image recording, storage and processing capabilities which are used in a new concept of automated in situ gas quantification by photo-optical detection. The design for an in situ high-speed image acquisition and automated data processing system is reported ("Bubblemeter"). New strategies have been followed with regards to back-light illumination, bubble extraction, automated image processing and data management. This paper presents the design of the novel method, its validation procedures and calibration experiments. The system will be positioned and recovered from the sea floor using a remotely operated vehicle (ROV). It is able to measure bubble flux rates up to 10 L/min with a maximum error of 33\% for worst case conditions. The Bubblemeter has been successfully deployed at a water depth of 1023 m at the Makran accretionary prism offshore Pakistan during a research expedition with R/V Meteor in November 2007.},
  langid = {english},
  file = {/Users/sid/Zotero/storage/9E67VFHD/Thomanek et al. - 2010 - Automated gas bubble imaging at sea floor &ndash; .pdf}
}

@misc{timadaTImadaRaspi4_freertos2024,
  title = {{{TImada}}/Raspi4\_freertos},
  author = {TImada},
  year = {2024},
  month = feb,
  url = {https://github.com/TImada/raspi4_freertos},
  urldate = {2024-02-29},
  abstract = {FreeRTOS UART sample porting to Raspberry Pi 4B.},
  copyright = {MIT}
}

@misc{tobiasgeislermesevageMachineLearningClassifiers2020,
  title = {Machine {{Learning Classifiers}} - {{The Algorithms}} \& {{How They Work}}},
  author = {{Tobias Geisler Mesevage}},
  year = {2020},
  month = dec,
  journal = {MonkeyLearn Blog},
  url = {https://monkeylearn.com/blog/what-is-a-classifier/},
  urldate = {2024-03-06},
  abstract = {Classifiers are machine learning algorithms used to organize and classify data. Learn how they work and what they can do to save time and money and streamline processes.},
  chapter = {Machine Learning},
  langid = {english},
  file = {/Users/sid/Zotero/storage/KIXHE6YQ/what-is-a-classifier.html}
}

@misc{universityofhawaiiPracticesScienceUnderwater,
  title = {Practices of {{Science}}: {{Underwater Photography}} and {{Videography}}},
  author = {{University of Hawai`i}},
  journal = {Practices of Science: Underwater Photography and Videography {\textbar} manoa.hawaii.edu/ExploringOurFluidEarth},
  url = {https://manoa.hawaii.edu/exploringourfluidearth/physical/ocean-depths/light-ocean/practices-science-underwater-photography-and-videography},
  urldate = {2024-02-13},
  langid = {english},
  file = {/Users/sid/Zotero/storage/AZT4HY4D/practices-science-underwater-photography-and-videography.html}
}

@misc{updatedWhatGlobalShutter2021,
  title = {What Is a Global Shutter -- and Why Is It so Important?},
  author = {last {updated}, Usman Dawood},
  year = {2021},
  month = feb,
  journal = {digitalcameraworld},
  url = {https://www.digitalcameraworld.com/news/what-is-a-global-shutter-and-why-is-it-so-important},
  urldate = {2024-02-24},
  abstract = {Global shutters enable cameras to read the whole sensor in one go, which helps prevent issues with rolling shutter},
  langid = {english},
  file = {/Users/sid/Zotero/storage/AD7BAAQR/what-is-a-global-shutter-and-why-is-it-so-important.html}
}

@inproceedings{villalpandoReconfigurableMachineVision2010,
  title = {Reconfigurable Machine Vision Systems Using {{FPGAs}}},
  booktitle = {2010 {{NASA}}/{{ESA Conference}} on {{Adaptive Hardware}} and {{Systems}}},
  author = {Villalpando, Carlos and Some, Raphael},
  year = {2010},
  month = jun,
  pages = {31--35},
  doi = {10.1109/AHS.2010.5546238},
  url = {https://ieeexplore.ieee.org/abstract/document/5546238?casa_token=YZkc1g9nyG8AAAAA:qaUYE7iAG0x2pnYW2X1EGUwYbQPc6B_ScahtXONJg3QzfRqGqnunPldYwFM0obJQSgb7UVRQwA},
  urldate = {2024-02-23},
  abstract = {FPGAs provide a flexible architecture for implementing many different types of machine vision algorithms. They allow heavily parallel portions of those algorithms to be accelerated and optimized for high specific performance (MIPS:Watt ratio). In comparison to ASICS, FPGAs enable low cost, quick turn prototyping and algorithm development as well as lower production costs for small quantity and one off applications. FPGAs also have the ability to be reprogrammed in flight, allowing them to be configured for different applications as mission needs evolve. JPL has developed a suite of machine vision IP cores to accelerate many common machine vision tasks used in robotic mobility applications. Modules such as stereo correlation for ranging, filtering, optical flow, area based correlation, feature detection, and image homography and rectification allow the real-time processing of image data using much smaller systems with much less power draw then an appropriately sized general purpose processor. These modules, along with a vision processing framework, are being re-cast in a generic plug and play form to allow rapid, low cost configuration, reconfiguration, evolution and adaptation of next generation machine vision systems for mobile robotics.},
  keywords = {Cameras,Correlation,Field programmable gate arrays,Hardware,IP networks,Machine vision,Pixel},
  file = {/Users/sid/Zotero/storage/5PF3W4KZ/5546238.html}
}

@misc{WhatFPGAField,
  title = {What Is an {{FPGA}}? {{Field Programmable Gate Array}}},
  shorttitle = {What Is an {{FPGA}}?},
  journal = {AMD},
  url = {https://www.xilinx.com/products/silicon-devices/fpga/what-is-an-fpga.html},
  urldate = {2024-02-23},
  abstract = {What is an FPGA - Field Programmable Gate Arrays are semiconductor devices that are based around a matrix of configurable logic blocks (CLBs) connected via programmable interconnects. FPGAs can be reprogrammed to desired application or functionality requirements after manufacturing.},
  langid = {english},
  file = {/Users/sid/Zotero/storage/BJ469M5J/what-is-an-fpga.html}
}

@book{yannickallardUnmannedUnderwaterVehicle2014,
  title = {Unmanned {{Underwater Vehicle}} ({{UUV}}) {{Information Study}}},
  author = {{Yannick Allard} and {Elisa Shahbazian}},
  year = {2014},
  month = nov,
  publisher = {Defence Research \& Development Canada, Atlantic Research Centre},
  url = {https://apps.dtic.mil/sti/pdfs/AD1004191.pdf},
  urldate = {2024-02-14},
  abstract = {Unmanned underwater vehicles UUV are any vehicles that are able to operate underwater without a human occupant. Smaller and cheaper autonomous underwater vehicles AUV are today very capable and gaining users. Large autonomous underwater vehicles are more expensive but they offer capabilities in some missions and applications that no other platforms can offer. However, using unmanned underwater vehicles in marine applications provide some challenges such as noisy communication, position uncertainty and the likelihood of robot failures. In addition, standards for data and information sharing are not well defined and, as mature as it is, the unmanned underwater vehicle field is still an emerging sector. Within the last decade, interest in UUV to be part of specific military, industrial and academic missions and applications have increased due to technological innovation and the evolution of their sensor payload. Missions such as persistent surveillance, anti-submarine warfare, oceanography and mine coutermeasure are amongst those where UUV capabilities far exceed those offered by other platforms. Canadas vast coastal areas could benefit from the introduction of UUVs to perform various roles. On one hand, their use is very cost-effective. On the other hand, they offer persistence and data quality that are not achievable using traditional methods. This usefulness is even more reflected in remote environments, where deploying personnel is a very costly alternatives. In order to enable the integration of the data and information provided by a UUV it is necessary to have a look in the underlying data and information sharing standards related to them. Achievement of interoperability between multiple national and international agencies is mandatory if one seeks to use the UUV to its full potential in support of the generation of more complete maritime domain awareness.},
  langid = {english}
}

@incollection{zelenkaGasBubbleShape2014,
  title = {Gas {{Bubble Shape Measurement}} and {{Analysis}}},
  booktitle = {Pattern {{Recognition}}},
  author = {Zelenka, Claudius},
  editor = {Jiang, Xiaoyi and Hornegger, Joachim and Koch, Reinhard},
  year = {2014},
  volume = {8753},
  pages = {743--749},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-11752-2_63},
  url = {https://link.springer.com/10.1007/978-3-319-11752-2_63},
  urldate = {2024-02-26},
  isbn = {978-3-319-11751-5 978-3-319-11752-2},
  langid = {english}
}

@article{zhangUnderwaterBubbleEscape2023,
  title = {Underwater Bubble Escape Volume Measurement Based on Passive Acoustic under Noise Factors: {{Simulation}} and Experimental Research},
  shorttitle = {Underwater Bubble Escape Volume Measurement Based on Passive Acoustic under Noise Factors},
  author = {Zhang, Yu and Yu, Yao and Rui, Xiaobo and Feng, Zhu and Zhang, Jin and Chen, Yong and Qi, Lei and Chen, Xi and Zhou, Xueqian},
  year = {2023},
  month = feb,
  journal = {Measurement},
  volume = {207},
  pages = {112400},
  issn = {0263-2241},
  doi = {10.1016/j.measurement.2022.112400},
  url = {https://www.sciencedirect.com/science/article/pii/S0263224122015974},
  urldate = {2024-02-24},
  abstract = {Passive acoustic methods are suitable for long-term seabed gas leak monitoring with high accuracy under the condition of low cost and simple experimental equipment. However, the impact of noise in complex underwater environments poses great challenges for measurements. In this paper, aiming at the quantitative detection problem, a theoretical model of the bubble generation process by underwater gas escape is established, and the mechanism of bubble acoustic signal generation is clarified. The model identification of bubble volume oscillation is realized through the complementary ensemble empirical mode decomposition (CEEMD) method. Then continuous bubbles are segmented by the normalized energy method to achieve a high-precision measurement of volume inversion. A measurement prototype is developed and tested in the lake with multiple noises caused by seawater disturbance, sea wind, and ships. The results showed that the measurement errors could be kept within 10\% even under the condition of strong noise interference.},
  keywords = {Ambient noise,Bubble,Carbon capture and storage,Passive acoustics,Prototype platform},
  file = {/Users/sid/Zotero/storage/RS77YW33/S0263224122015974.html}
}
